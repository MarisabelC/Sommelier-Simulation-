{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"conditional.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"2H4GUMclT1WP","colab_type":"text"},"cell_type":"markdown","source":["# Conditional Model\n","\n","CS4200 Final Project \n","\n","https://www.cpp.edu/~dmhughes/cs4200_project/blogpost.html"]},{"metadata":{"id":"imErSNxIUCfx","colab_type":"text"},"cell_type":"markdown","source":["**Connecting to Google Drive**"]},{"metadata":{"id":"oHvHpfaXH1ux","colab_type":"code","outputId":"eb955bc1-b0bc-44c0-f7b8-5fbc26186bb8","executionInfo":{"status":"ok","timestamp":1543772583868,"user_tz":480,"elapsed":30938,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"cell_type":"code","source":["!pip install PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import os\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting PyDrive\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n","\u001b[K    100% |████████████████████████████████| 993kB 20.9MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.11.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.4)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.2)\n","Building wheels for collected packages: PyDrive\n","  Running setup.py bdist_wheel for PyDrive ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n","Successfully built PyDrive\n","Installing collected packages: PyDrive\n","Successfully installed PyDrive-1.3.1\n"],"name":"stdout"}]},{"metadata":{"id":"oCRZ1-W0P_P3","colab_type":"code","outputId":"4a3e1f4e-388d-4fde-fa24-516973dd8a87","executionInfo":{"status":"ok","timestamp":1543772588428,"user_tz":480,"elapsed":35435,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["if os.path.exists(\"winemag-data-130k-v2.csv\"):\n","  print(\"Wine csv already exists\")\n","else:\n","  download_test = drive.CreateFile({'id': '127NdtnUoFh_nAJOwYaj_5i9uBof2lwe1'})\n","  wine_file = download_test.GetContentFile('wine.zip')\n","  #print('Downloaded content \"{}\"'.format(len(wine_file)))\n","\n","  !unzip wine.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  wine.zip\n","  inflating: winemag-data-130k-v2.csv  \n"],"name":"stdout"}]},{"metadata":{"id":"I0Goi5lkQGj_","colab_type":"code","outputId":"d4fb18df-777f-4e0c-ebda-fc5b5afde8c3","executionInfo":{"status":"ok","timestamp":1543772589719,"user_tz":480,"elapsed":36695,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import keras\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Activation,CuDNNLSTM,Dropout, GRU, CuDNNGRU, Flatten\n","from keras.callbacks import LambdaCallback, ModelCheckpoint, ReduceLROnPlateau,Callback, History\n","from keras.optimizers import Adam\n","from keras.utils.data_utils import get_file\n","from keras.layers.embeddings import Embedding\n","import numpy as np\n","import pandas as pd\n","import random\n","import sys\n","import io\n","import os\n","import matplotlib.pyplot as plt\n","import pickle\n","import math\n","import time"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"TjuFGtqeUX0H","colab_type":"text"},"cell_type":"markdown","source":["**Condtioning context functions (for price)**"]},{"metadata":{"id":"WfHibmQZnZph","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_price_category(min_price, max_price, num_cat):\n","  cat_size = int((max_price - min_price) / num_cat)\n","  temp = [min_price]\n","  for i in range(1, num_cat):\n","    temp.append(min_price + i*cat_size)\n","  return temp\n","\n","# print(\"max \",price_df.max(), \" min \", price_df.min() )    \n","# price_cats = create_price_category(price_df.min(), price_df.max(), 20)\n","# print(price_cats, len(price_cats))\n","\n","def price_to_category(price, price_cats):\n","  price_i = 0\n","  \n","  if price < price_cats[0]:\n","    price_i = 0\n","  elif price > price_cats[len(price_cats)-1]:\n","    price_i = len(price_cats)-1\n","  else:\n","    for i in range(1, len(price_cats)):\n","      if price >= price_cats[i-1] and price <= price_cats[i]:\n","        if abs(price - price_cats[i-1]) > abs(price - price_cats[i]):\n","          price_i = i\n","          break\n","        else:\n","          price_i = i-1\n","          break\n","    \n","        \n","  return price_i\n","  \n","# print(125, \" \", cats[priceCategory(125, cats)] ) \n","# print(109, \" \", cats[priceCategory(109, cats)] ) \n","# print(700, \" \", cats[priceCategory(700, cats)] ) \n","# print(14, \" \", cats[priceCategory(14, cats)] ) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jst_Kp8vUZBR","colab_type":"text"},"cell_type":"markdown","source":["**Handle the CSV as a pandas dataframe**\n","\n","**Also create a list of [(character, price)]**\n","\n","**Create vocab data structures**"]},{"metadata":{"id":"eS4TOYACQKdo","colab_type":"code","outputId":"46b1ff45-52ef-49d9-e237-6be96ff31cc8","executionInfo":{"status":"ok","timestamp":1543772594308,"user_tz":480,"elapsed":41262,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"cell_type":"code","source":["df = pd.read_csv('winemag-data-130k-v2.csv')\n","print(list(df)) # column names \n","# get wine reviews that have points>=94 \n","df= df[df['points']>=94]\n","df= df[df['country']==\"US\"]\n","print (df.shape)\n","\n","num_sample=df.shape[0] \n","\n","price_df = df[df.columns[5]]\n","print(\"max \",price_df.max(), \" min \", price_df.min() )\n","\n","\n","#get the description column that contains win reviews\n","desc_df = df[df.columns[2]]\n","print(\"First description: \", desc_df.values[0])\n","\n","# remove new line characters\n","desc_df= desc_df.replace({r'\\n+': ''}, regex=True)\n","\n","# remove duplicated reviews\n","desc_df=desc_df.drop_duplicates()\n","print(\"After dropping duplicates: \", desc_df.shape)\n","\n","text_file = open(\"wine_review_text.txt\", \"w\")\n","for line in desc_df.values:\n","  text_file.write(line)\n","text_file.close()\n","\n","\n","text_file = open(\"wine_review_text.txt\", \"r\")\n","text = text_file.read()\n","length_text = len(text)\n","print(\"length_text (the number of characters)\", length_text)\n","#get the set of characters in the language\n","set_chars = sorted(list(set(text)))\n","print(\"NumChars in lang = \",len(set_chars),\", set of chars in the lang: \", set_chars)\n","char_to_int = dict((c, i) for i, c in enumerate(set_chars))\n","int_to_char = dict((i, c) for i, c in enumerate(set_chars))\n","\n","cut_length=60\n","num_price_cats = 20\n","\n","price_cats = create_price_category(price_df.min(), price_df.max(), num_price_cats)\n","\n","combined_text_price = []  \n","for i, line in enumerate(desc_df.values):\n","  for ch in line:\n","    combined_text_price.append((char_to_int[ch], price_to_category(price_df.values[i], price_cats)))\n","\n","print(combined_text_price[1000:1500])    \n","    \n","#print(\"combined_text_price\", combined_text_price[0])\n","del desc_df\n","del df\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["['Unnamed: 0', 'country', 'description', 'designation', 'points', 'price', 'province', 'region_1', 'region_2', 'taster_name', 'taster_twitter_handle', 'title', 'variety', 'winery']\n","(2787, 14)\n","max  625.0  min  16.0\n","First description:  Citrus-kissed saltiness lies at the core of this incredibly delicious, deliriously crafted wine, from the great grape grower in the heart of the Russian River Valley. Beautifully crisp, it lingers in stony minerality and a freshness of apricot, memorable from first sip to last.\n","After dropping duplicates:  (2715,)\n","length_text (the number of characters) 932982\n","NumChars in lang =  101 , set of chars in the lang:  [' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'É', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ñ', 'ô', 'ö', 'ú', 'û', 'ü', '–', '—', '‘', '’', '“', '”', '…']\n","[(70, 1), (0, 1), (61, 1), (71, 1), (0, 1), (72, 1), (60, 1), (57, 1), (0, 1), (71, 1), (72, 1), (53, 1), (70, 1), (0, 1), (67, 1), (58, 1), (0, 1), (53, 1), (0, 1), (74, 1), (57, 1), (70, 1), (77, 1), (0, 1), (58, 1), (61, 1), (66, 1), (57, 1), (0, 1), (49, 1), (61, 1), (66, 1), (56, 1), (57, 1), (70, 1), (64, 1), (57, 1), (53, 1), (0, 1), (64, 1), (61, 1), (66, 1), (57, 1), (73, 1), (68, 1), (12, 1), (0, 1), (30, 1), (53, 1), (70, 1), (63, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (56, 1), (57, 1), (57, 1), (68, 1), (64, 1), (77, 1), (0, 1), (55, 1), (67, 1), (66, 1), (55, 1), (57, 1), (66, 1), (72, 1), (70, 1), (53, 1), (72, 1), (57, 1), (56, 1), (10, 1), (0, 1), (61, 1), (72, 1), (6, 1), (71, 1), (0, 1), (62, 1), (53, 1), (65, 1), (65, 1), (57, 1), (56, 1), (0, 1), (75, 1), (61, 1), (72, 1), (60, 1), (0, 1), (54, 1), (64, 1), (53, 1), (55, 1), (63, 1), (0, 1), (55, 1), (60, 1), (57, 1), (70, 1), (70, 1), (77, 1), (0, 1), (58, 1), (70, 1), (73, 1), (61, 1), (72, 1), (10, 1), (0, 1), (53, 1), (66, 1), (66, 1), (67, 1), (72, 1), (53, 1), (72, 1), (57, 1), (56, 1), (0, 1), (75, 1), (61, 1), (72, 1), (60, 1), (0, 1), (53, 1), (66, 1), (61, 1), (71, 1), (57, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (71, 1), (60, 1), (67, 1), (75, 1), (61, 1), (66, 1), (59, 1), (0, 1), (53, 1), (0, 1), (60, 1), (61, 1), (66, 1), (72, 1), (0, 1), (67, 1), (58, 1), (0, 1), (59, 1), (73, 1), (66, 1), (65, 1), (57, 1), (72, 1), (53, 1), (64, 1), (12, 1), (0, 1), (46, 1), (60, 1), (57, 1), (0, 1), (72, 1), (53, 1), (66, 1), (66, 1), (61, 1), (66, 1), (71, 1), (0, 1), (53, 1), (70, 1), (57, 1), (0, 1), (70, 1), (61, 1), (68, 1), (57, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (72, 1), (53, 1), (71, 1), (72, 1), (57, 1), (0, 1), (67, 1), (58, 1), (0, 1), (55, 1), (64, 1), (57, 1), (53, 1), (66, 1), (0, 1), (57, 1), (53, 1), (70, 1), (72, 1), (60, 1), (12, 1), (0, 1), (46, 1), (60, 1), (61, 1), (71, 1), (0, 1), (61, 1), (71, 1), (0, 1), (53, 1), (0, 1), (58, 1), (61, 1), (66, 1), (57, 1), (0, 1), (55, 1), (53, 1), (66, 1), (56, 1), (61, 1), (56, 1), (53, 1), (72, 1), (57, 1), (0, 1), (58, 1), (67, 1), (70, 1), (0, 1), (53, 1), (59, 1), (61, 1), (66, 1), (59, 1), (12, 1), (0, 1), (30, 1), (70, 1), (61, 1), (66, 1), (63, 1), (0, 1), (66, 1), (67, 1), (75, 1), (0, 1), (72, 1), (60, 1), (70, 1), (67, 1), (73, 1), (59, 1), (60, 1), (0, 1), (16, 1), (14, 1), (17, 1), (14, 1), (12, 1), (29, 1), (67, 1), (65, 1), (68, 1), (67, 1), (71, 1), (57, 1), (56, 1), (10, 1), (0, 1), (55, 1), (67, 1), (65, 1), (68, 1), (64, 1), (57, 1), (76, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (55, 1), (67, 1), (65, 1), (68, 1), (64, 1), (57, 1), (72, 1), (57, 1), (10, 1), (0, 1), (72, 1), (60, 1), (61, 1), (71, 1), (0, 1), (65, 1), (57, 1), (64, 1), (64, 1), (67, 1), (75, 1), (0, 1), (75, 1), (61, 1), (66, 1), (57, 1), (0, 1), (61, 1), (71, 1), (0, 1), (74, 1), (57, 1), (70, 1), (77, 1), (0, 1), (55, 1), (67, 1), (65, 1), (58, 1), (67, 1), (70, 1), (72, 1), (53, 1), (54, 1), (64, 1), (57, 1), (0, 1), (61, 1), (66, 1), (0, 1), (61, 1), (72, 1), (71, 1), (0, 1), (71, 1), (63, 1), (61, 1), (66, 1), (12, 1), (0, 1), (46, 1), (67, 1), (73, 1), (55, 1), (60, 1), (57, 1), (71, 1), (0, 1), (67, 1), (58, 1), (0, 1), (67, 1), (53, 1), (63, 1), (10, 1), (0, 1), (72, 1), (67, 1), (54, 1), (53, 1), (55, 1), (55, 1), (67, 1), (10, 1), (0, 1), (56, 1), (70, 1), (61, 1), (57, 1), (56, 1), (0, 1), (68, 1), (64, 1), (73, 1), (65, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (55, 1), (53, 1), (70, 1), (56, 1), (53, 1), (65, 1), (67, 1), (65, 1), (0, 1), (58, 1), (61, 1), (64, 1), (64, 1), (0, 1), (72, 1), (60, 1), (57, 1), (0, 1), (53, 1), (70, 1), (67, 1), (65, 1), (53, 1), (10, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (70, 1), (61, 1), (68, 1), (57, 1), (0, 1), (54, 1), (73, 1), (72, 1), (0, 1), (66, 1), (67, 1), (72, 1), (0, 1), (67, 1), (74, 1), (57, 1), (70, 1), (70, 1), (61, 1), (68, 1), (57, 1), (0, 1), (54, 1), (64, 1), (53, 1), (55, 1), (63, 1), (0, 1), (55, 1), (60, 1), (57, 1), (70, 1), (70, 1), (77, 1), (10, 1), (0, 1), (72, 1), (53, 1), (65, 1), (53, 1), (70, 1), (61, 1), (66, 1), (56, 1), (0, 1), (53, 1), (66, 1), (56, 1), (0, 1), (55, 1), (67, 1), (64, 1), (53, 1), (0, 1), (58, 1), (64, 1), (53, 1), (74, 1), (67, 1), (70, 1), (71, 1), (0, 1), (58, 1), (64, 1), (67, 1), (67, 1), (56, 1), (0, 1), (72, 1), (60, 1), (57, 1), (0, 1), (68, 1), (53, 1), (64, 1), (53, 1)]\n"],"name":"stdout"}]},{"metadata":{"id":"usFnz3leVQXu","colab_type":"text"},"cell_type":"markdown","source":["**Sequence splitting function**"]},{"metadata":{"id":"T5qvyDlsQVKj","colab_type":"code","colab":{}},"cell_type":"code","source":["#break it down  the text into chunks of 90k characters each\n","def get_data_from_chunk_cond(combined_text_price, step=3, num_one_hots=2):\n","  \n","  seqs = []\n","  next_chars_to_seq = []\n","\n","  for i in range(0, len(combined_text_price)-cut_length, step):\n","    seqs.append(combined_text_price[i: i+cut_length])\n","    next_chars_to_seq.append(combined_text_price[i+cut_length])\n","\n","  print(\"Number of sequences: \", len(seqs) )  \n","\n","  #create vectors X and y for fitting model\n","  X = np.zeros((len(seqs), cut_length, num_one_hots), dtype=np.uint)\n","  y = np.zeros((len(seqs), num_one_hots), dtype=np.uint)\n","  for i, seq in enumerate(seqs):\n","      for j, pair in enumerate(seq):\n","        X[i, j, 0] = pair[0]\n","        X[i, j, 1] = pair[1]\n","      y[i, 0] = next_chars_to_seq[i][0]\n","      y[i, 1] = next_chars_to_seq[i][1]\n","\n","      \n","  X_char = np.array([ [word[0]  for word in seq]  for seq in X])\n","  X_price = np.array([ [seq[-1][1]] for seq in X])\n","  y_ = np.array([keras.utils.to_categorical(word[0], len(set_chars), dtype='int32')  for word in y])\n","  \n","  del seqs\n","  del next_chars_to_seq\n","  del X\n","  del y\n","  \n","  return [X_char, X_price, y_]\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qAtGDGuHVdBr","colab_type":"text"},"cell_type":"markdown","source":["** Build Condtional model in functional Keras style**"]},{"metadata":{"id":"5UZT0C3uQZLN","colab_type":"code","outputId":"534556ef-7e1d-4ad6-dcdf-7a8db8b53a6e","executionInfo":{"status":"ok","timestamp":1543772602028,"user_tz":480,"elapsed":48949,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"cell_type":"code","source":["from keras import backend as K\n","K.clear_session()\n","\n","print('Building Model')\n","#first input layer\n","char_input = Input(shape=(None,), dtype='int32', name='char_input')\n","char_embedd = Embedding(output_dim=10, input_dim=cut_length)(char_input)\n","\n","x = CuDNNLSTM(256, return_sequences=True)(char_embedd)\n","x = Dropout(0.3)(x)\n","char_encoded = CuDNNLSTM(256)(x)\n","\n","#second input layer\n","price_input = Input(shape=(1,), name='price_input')\n","\n","#combine the output of the left and right models\n","combined = keras.layers.concatenate([char_encoded, price_input])\n","\n","x = Dense(128, activation='relu')(combined)\n","x = Dropout(0.3)(x)\n","final_output = Dense(len(set_chars), activation='softmax')(x)\n","\n","print(final_output.shape)\n","\n","model = Model(inputs=[char_input, price_input], outputs=final_output)\n","\n","def load_model():\n","  \n","  if os.path.exists(\"weights.hdf5\"):\n","    print(\"Loading transfer weights...\")\n","    model.load_weights(\"weights.hdf5\")\n","  else:\n","    print(\"Starting new model weights...\")\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Building Model\n","(?, 101)\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","char_input (InputLayer)         (None, None)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 10)     600         char_input[0][0]                 \n","__________________________________________________________________________________________________\n","cu_dnnlstm_1 (CuDNNLSTM)        (None, None, 256)    274432      embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n","__________________________________________________________________________________________________\n","cu_dnnlstm_2 (CuDNNLSTM)        (None, 256)          526336      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","price_input (InputLayer)        (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 257)          0           cu_dnnlstm_2[0][0]               \n","                                                                 price_input[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          33024       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 101)          13029       dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 847,421\n","Trainable params: 847,421\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"5RuDIZ1SVylf","colab_type":"text"},"cell_type":"markdown","source":["**Addtional Keras Functions**\n","- sample() provides for choosing a character based on temperature/diversity\n","- on_train_end() generates text at the end of training the model\n","- also various Keras callbacks"]},{"metadata":{"id":"zcFAH7cxQjiI","colab_type":"code","colab":{}},"cell_type":"code","source":["#Function to sample index from probab array\n","#    -temp is a parameter used in softmax func which controls level of newness\n","#    -temp=1 constricts sampling and leads to less diverse/more repetitive text\n","#i.e.\n","#The “sampling index” process will add some variety to the final result by generating some randomness with the given prediction.\n","#If the temperature is very small, it will always pick the index with highest predicted probability.\n","def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64') #convert one-hot encoding to an array of float64\n","    preds = np.log(preds) / temperature         #log each value elementwise then perform elementwise division by the temperature\n","    #apply softmax\n","    exp_preds = np.exp(preds)                   \n","    preds = exp_preds / np.sum(exp_preds)\n","    #create a one-hot encoding\n","    probas = np.random.multinomial(1, preds, 1) \n","    return np.argmax(probas)      #argmax = Returns the indices of the maximum values along an axis.                \n","\n","\n","# Function called at the end of an training\n","def on_train_end(_):\n","    #print('\\n----- Generating text after Epoch: %d' % epoch)\n","    start_i = random.randint(0, length_text - cut_length - 1)\n","    \n","    sentence = combined_text_price[start_i: start_i + cut_length]\n","    price_i = sentence[-1][1]\n","    sentence_in_chars =''.join ([int_to_char[c[0]] for c in sentence])\n","    print('----- Generating with seed: \"' , sentence_in_chars , '\" and price=' , price_cats[price_i] , ':')\n","    \n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('----- diversity:', diversity)\n","        generated = ''\n","        sentence = combined_text_price[start_i: start_i + cut_length]\n","        price_i = sentence[-1][1]\n","        sentence_in_chars =''.join ([int_to_char[c[0]] for c in sentence])\n","        generated += sentence_in_chars\n","        sys.stdout.write(generated)\n","        for i in range(cut_length):\n","            X_pred_char = np.array([letter[0] for letter in sentence])\n","            X_pred_char = np.expand_dims(X_pred_char, axis=0)\n","            X_pred_price = np.array([price_i])                      #maybe price_i will work here\n","            X_pred_price = np.expand_dims(X_pred_price, axis=0)\n","            preds = model.predict([X_pred_char,X_pred_price], verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            #print(\" index:\",next_index )\n","            next_char = int_to_char[next_index]\n","\n","            generated += next_char\n","            sentence = sentence[1:] + [(next_index,price_i)]\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()\n","\n","        \n","#callback list        \n","history = History()\n","\n","#lambdacallback = LambdaCallback()\n","lambdacallback = LambdaCallback(on_train_end=on_train_end)\n","\n","filepath=\"weights.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","\n","reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n","\n","callbacks = [history, checkpoint, reduce_lr, lambdacallback]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MfgBTWXkWf1r","colab_type":"text"},"cell_type":"markdown","source":["**Functions to load loss history from file in order to continue training from a weights file**"]},{"metadata":{"id":"tGT878SfAyys","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_loss_history(file_loss= \"lossHistory\"):\n","  #open the loss history report file for reading\n","  history_dict={}\n","\n","  if os.path.exists(file_loss):\n","    file_object= open(file_loss,'rb') \n","    history_dict = pickle.load(file_object)\n","    file_object.close()\n","    print(\"Loading loss history report...\")\n","\n","  else:\n","    print(\"Starting new loss history report...\")\n","  \n","  return history_dict\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iYXxbuCoVJfY","colab_type":"code","colab":{}},"cell_type":"code","source":["def save_loss_history(history_dict,file_loss= \"lossHistory\"):\n","  \n","  if(history_dict):\n","    history_dict['loss'].extend(history_model.history['loss'])\n","    #history_dict['val_loss'].extend(history_model.history['val_loss'])\n","  else:\n","    history_dict=history_model.history\n","  \n","  # open the loss history report file for writing\n","  fileObject = open(file_loss,'wb') \n","\n","  # write the object a to the lossHistory file\n","  pickle.dump(history_dict,fileObject)\n","  fileObject.close()\n","  print(\"Saving loss history report ...\")\n","  return history_dict\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Ck5Bpx3t-Ts","colab_type":"code","outputId":"bce040c1-4337-4622-8c09-33bd066ed6ec","executionInfo":{"status":"ok","timestamp":1543772626913,"user_tz":480,"elapsed":73795,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"cell_type":"code","source":["print(\"Chunk Data into X and y\")\n","X_char, X_price, y = get_data_from_chunk_cond(combined_text_price)  \n","\n","print(X_char.shape, len(X_char), X_char[0])\n","print(X_price.shape, len(X_price), X_price[0])\n","print(y.shape, len(y), y[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Chunk Data into X and y\n","Number of sequences:  310974\n","(310974, 60) 310974 [29 61 72 70 73 71 11 63 61 71 71 57 56  0 71 53 64 72 61 66 57 71 71  0\n"," 64 61 57 71  0 53 72  0 72 60 57  0 55 67 70 57  0 67 58  0 72 60 61 71\n","  0 61 66 55 70 57 56 61 54 64 77  0]\n","(310974, 1) 310974 [2]\n","(310974, 101) 310974 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"],"name":"stdout"}]},{"metadata":{"id":"8QHMsYXLW91V","colab_type":"text"},"cell_type":"markdown","source":["**Call the compile, fitting, and saving function**"]},{"metadata":{"id":"TvlF9HysRMHD","colab_type":"code","outputId":"62dc896e-2dd2-4d99-c0ea-498311489c7c","executionInfo":{"status":"error","timestamp":1543779747370,"user_tz":480,"elapsed":3256140,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":1768}},"cell_type":"code","source":["!rm weights.hdf5\n","!rm lossHistory\n","\n","batch_size=128\n","load_model()\n","history_dict=load_loss_history()\n","\n","print(\"fit model\")\n","start_time = time.time()\n","history_model=model.fit([X_char,X_price], y, batch_size=128, epochs=50, callbacks=callbacks, verbose=1, validation_split=0) \n","end_time = time.time()\n","print(\"Wall Time to fit model: \", end_time - start_time)\n","\n","\n","history_dict=save_loss_history(history_dict)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'weights.hdf5': No such file or directory\n","rm: cannot remove 'lossHistory': No such file or directory\n","Starting new model weights...\n","Starting new loss history report...\n","fit model\n","Epoch 1/50\n","310974/310974 [==============================] - 136s 437us/step - loss: 2.7729\n","\n","Epoch 00001: loss improved from inf to 2.77293, saving model to weights.hdf5\n","Epoch 2/50\n","310974/310974 [==============================] - 131s 423us/step - loss: 2.3539\n","\n","Epoch 00002: loss improved from 2.77293 to 2.35391, saving model to weights.hdf5\n","Epoch 3/50\n","310974/310974 [==============================] - 131s 422us/step - loss: 2.1942\n","\n","Epoch 00003: loss improved from 2.35391 to 2.19415, saving model to weights.hdf5\n","Epoch 4/50\n","310974/310974 [==============================] - 134s 432us/step - loss: 2.1060\n","\n","Epoch 00004: loss improved from 2.19415 to 2.10599, saving model to weights.hdf5\n","Epoch 5/50\n","310974/310974 [==============================] - 229s 738us/step - loss: 2.0417\n","\n","Epoch 00005: loss improved from 2.10599 to 2.04168, saving model to weights.hdf5\n","Epoch 6/50\n","310974/310974 [==============================] - 238s 764us/step - loss: 1.9977\n","\n","Epoch 00006: loss improved from 2.04168 to 1.99770, saving model to weights.hdf5\n","Epoch 7/50\n","310974/310974 [==============================] - 238s 765us/step - loss: 1.9551\n","\n","Epoch 00007: loss improved from 1.99770 to 1.95508, saving model to weights.hdf5\n","Epoch 8/50\n","310974/310974 [==============================] - 237s 761us/step - loss: 1.9234\n","\n","Epoch 00008: loss improved from 1.95508 to 1.92344, saving model to weights.hdf5\n","Epoch 9/50\n","310974/310974 [==============================] - 237s 763us/step - loss: 1.8928\n","\n","Epoch 00009: loss improved from 1.92344 to 1.89282, saving model to weights.hdf5\n","Epoch 10/50\n","310974/310974 [==============================] - 237s 762us/step - loss: 1.8709\n","\n","Epoch 00010: loss improved from 1.89282 to 1.87086, saving model to weights.hdf5\n","Epoch 11/50\n","310974/310974 [==============================] - 237s 762us/step - loss: 1.8480\n","\n","Epoch 00011: loss improved from 1.87086 to 1.84804, saving model to weights.hdf5\n","Epoch 12/50\n","310974/310974 [==============================] - 237s 762us/step - loss: 1.8267\n","\n","Epoch 00012: loss improved from 1.84804 to 1.82665, saving model to weights.hdf5\n","Epoch 13/50\n","310974/310974 [==============================] - 236s 760us/step - loss: 1.8103\n","\n","Epoch 00013: loss improved from 1.82665 to 1.81035, saving model to weights.hdf5\n","Epoch 14/50\n","310974/310974 [==============================] - 237s 761us/step - loss: 1.7914\n","\n","Epoch 00014: loss improved from 1.81035 to 1.79139, saving model to weights.hdf5\n","Epoch 15/50\n","310974/310974 [==============================] - 236s 759us/step - loss: 1.7768\n","\n","Epoch 00015: loss improved from 1.79139 to 1.77678, saving model to weights.hdf5\n","Epoch 16/50\n","310974/310974 [==============================] - 237s 762us/step - loss: 1.7636\n","\n","Epoch 00016: loss improved from 1.77678 to 1.76359, saving model to weights.hdf5\n","Epoch 17/50\n","310974/310974 [==============================] - 238s 765us/step - loss: 1.7508\n","\n","Epoch 00017: loss improved from 1.76359 to 1.75077, saving model to weights.hdf5\n","Epoch 18/50\n","310974/310974 [==============================] - 239s 768us/step - loss: 1.7391\n","\n","Epoch 00018: loss improved from 1.75077 to 1.73914, saving model to weights.hdf5\n","Epoch 19/50\n","310974/310974 [==============================] - 242s 780us/step - loss: 1.7290\n","\n","Epoch 00019: loss improved from 1.73914 to 1.72899, saving model to weights.hdf5\n","Epoch 20/50\n","310974/310974 [==============================] - 241s 774us/step - loss: 1.7169\n","\n","Epoch 00020: loss improved from 1.72899 to 1.71686, saving model to weights.hdf5\n","Epoch 21/50\n","310974/310974 [==============================] - 244s 783us/step - loss: 1.7084\n","\n","Epoch 00021: loss improved from 1.71686 to 1.70842, saving model to weights.hdf5\n","Epoch 22/50\n","310974/310974 [==============================] - 242s 778us/step - loss: 1.7000\n","\n","Epoch 00022: loss improved from 1.70842 to 1.70003, saving model to weights.hdf5\n","Epoch 23/50\n","310974/310974 [==============================] - 241s 776us/step - loss: 1.6941\n","\n","Epoch 00023: loss improved from 1.70003 to 1.69409, saving model to weights.hdf5\n","Epoch 24/50\n","310974/310974 [==============================] - 241s 775us/step - loss: 1.6840\n","\n","Epoch 00024: loss improved from 1.69409 to 1.68397, saving model to weights.hdf5\n","Epoch 25/50\n","114816/310974 [==========>...................] - ETA: 2:31 - loss: 1.6724Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"metadata":{"id":"Rf1p6VhKJJHH","colab_type":"code","colab":{}},"cell_type":"code","source":["model.load_weights(\"weights.hdf5\") #load saved model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AIqSSS73XMKg","colab_type":"text"},"cell_type":"markdown","source":["**Function that does a similar function to on_train_end but can be called as long as the model has been loaded**"]},{"metadata":{"id":"PWxMg0ad52iY","colab_type":"code","outputId":"e007f3df-5a8d-4e26-e624-96c58afc39b0","executionInfo":{"status":"ok","timestamp":1543779801664,"user_tz":480,"elapsed":46603,"user":{"displayName":"Marisabel Chang","photoUrl":"https://lh4.googleusercontent.com/-a6vMGD9uWNA/AAAAAAAAAAI/AAAAAAAAABA/1OWxPmxzQ0s/s64/photo.jpg","userId":"14691282743771071263"}},"colab":{"base_uri":"https://localhost:8080/","height":445}},"cell_type":"code","source":["def make_pred(list_of_prices):\n","  \n","  start_i = random.randint(0, len(text) - cut_length - 1)\n","  \n","  for passed_price in list_of_prices:\n","    price_i = price_to_category(passed_price, price_cats)\n","    generated = ''\n","    sentence = combined_text_price[start_i: start_i + cut_length]\n","    sentence_in_chars =''.join ([int_to_char[c[0]] for c in sentence])\n","    generated += sentence_in_chars\n","    print('\\n----- Generating with seed: \"' , sentence_in_chars , '\" and price=' , price_cats[price_i] , ':\\n')\n","\n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('----- diversity:', diversity)\n","        generated = ''\n","        sentence = combined_text_price[start_i: start_i + cut_length]\n","        sentence_in_chars =''.join ([int_to_char[c[0]] for c in sentence])\n","        generated += sentence_in_chars\n","        sys.stdout.write(generated)\n","        for i in range(400):\n","            X_pred_char = np.array([letter[0] for letter in sentence])\n","            X_pred_char = np.expand_dims(X_pred_char, axis=0)\n","            #print(\"\\nX_pred_char\",  X_pred_char.shape)\n","            X_pred_price = np.array([price_i])                      #maybe price_i will work here\n","            X_pred_price = np.expand_dims(X_pred_price, axis=0)\n","            #print(\"X_pred_price\", X_pred_price.shape, X_pred_price)\n","            preds = model.predict([X_pred_char,X_pred_price], verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            #print(\" index:\",next_index )\n","            next_char = int_to_char[next_index]\n","\n","            generated += next_char\n","            sentence = sentence[1:] + [(next_index,price_i)]\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()\n","      \n","make_pred([600,10])\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","----- Generating with seed: \" ing, a standout for the producer and the appellation in a pi \" and price= 586.0 :\n","\n","----- diversity: 0.2\n","ing, a standout for the producer and the appellation in a pine of tanoiy fla"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["vors of black cherryes, cherries, cassis, coerries, cherries, cassis, ricoa, coovamon and chocolate and coerry flavors ard a sine tf coanberry and cherry fravors are teartess and tiasted in tas ard soe finish. The tine is a roue tiat wase ih the firit and a sine of caramel and chonamon flavors are tearty and sine coerry flavors ard a sine of chanberry and cherry fravors ard a sont \n","----- diversity: 0.5\n","ing, a standout for the producer and the appellation in a pise if sote ran and black currant flavors. Al ihsm a barance oh ohe finish. It sool the fiui bodied, and the trne is tanered and complex flavors of cherryes, cherries and cassis fluit and teat and cherry fravors are weasyng a seartess tight oht fin al heast tie yise if this iine ii iight and seas oaner of tav, and she salnins are sire and al inght iite if the alpmas flavors of ttoe pite and pan fla\n","----- diversity: 1.0\n","ing, a standout for the producer and the appellation in a pitue tf seach and roange seel ti oligerine, exegant flavors of ntrce perb and Crosied jiieyal acidity and iieet deepsy riiened taktalal niining a ltue that aryoner clmfidence— tidered aloeady frrmt ard bloghtened, whch agaynst milerye and alrentation of the moul chmcentration and rmanped denelop, dark beau, ranitle ietpet, lenwety man and crnnamon flavors ane wwtckiig tiue, whph spicyes of movk her\n","----- diversity: 1.2\n","ing, a standout for the producer and the appellation in a pigh, and sue nrchness iito mte apoucit and chean flavors rhto buended frr toggestsng frn torg tine.The wosiage foesh, ar zerl iiycy cllmuex and firm bodied fravor ard tusmytatiess an tayts Cabernet, iooh uhiplest, cetlar. Shio brge tf toosgnes tnen tie cenebration and inbise rotniern foavors, tiwm isne.This whn grapes frn sie Calimes Rew chsd bu Ite niavty of girmnyce wt tuu thaset oavt tonslgh al \n","\n","----- Generating with seed: \" ing, a standout for the producer and the appellation in a pi \" and price= 16.0 :\n","\n","----- diversity: 0.2\n","ing, a standout for the producer and the appellation in a pine tf san and searher and chovamon flavors, with a soue tf bak leaf, seather, coerry and cassis, with a sone of coerry and cherry and cherry fluit flavors that are delicious and a soue of black cherry and cherry flavors that are a sole oh the palate, with a sine of serbs and a sone of coocolate and choa, thth a sone tf saniiya and sioe petals, tith a sine of saniiya and cherry flavors are a sirt o\n","----- diversity: 0.5\n","ing, a standout for the producer and the appellation in a piue tf grapes and teramn ii the finish. The fluit and a black pepper, ald sarer one pext seast th th the pinne are ihe palate ieep and puteralsty and al insii woast oioh tf haniberry and red cuerry fluit io tarp fravors of wire chole flavors. The aromas are conplex, wi's paresed ian, and ss a loate oi si the frnish. The fruit is a sutery of tieet vex sak, with a coarsically balanced and rearhy of b\n","----- diversity: 1.0\n","ing, a standout for the producer and the appellation in a pinderfully beautiful Noundo nf semgtt, the coigltated sp fons tirces. Sede, nabeled tirlctured an ttsuogh 2038.This rienent anpuas of jmse solce, vobtlcus, guaphite and miilu lf sotne fravors, crastic ierbal, itisgh yr ot the aptellation, mhis rsterariyy piuln iemturi and riampay that escellionally delightful wi the nogh nobtte, lutl werus imregranion, ththaii, rtuched with define of earth, drffere\n","----- diversity: 1.2\n","ing, a standout for the producer and the appellation in a pipg, annencate of 100% an teast atlond jich, ald biend ohat reaz-celebratiog wnxe, an eartyy mm tatlny oannin grames, groen shch additional tf herpogieys comnellinng iu ans lhe oalate ielghh and pipe shttwobeel mh be, and thrh come tf cassis fluit, ficused tn ihe frlish, itihinnoue and beautifully tpr-ttgttlg exackes pade overe's hoihage pn shl nu 2020.toe lopselce iian bui thlsers, 10% Cabernet ba\n"],"name":"stdout"}]},{"metadata":{"id":"_jWk62bRVe-L","colab_type":"code","colab":{}},"cell_type":"code","source":["# print (history_dict['loss'])\n","# # Plot training & validation loss values\n","# plt.plot(history_dict['loss'])\n","# plt.title('Model loss')\n","# plt.ylabel('Loss')\n","# plt.xlabel('Epoch')\n","# plt.legend(['Train'], loc='upper left')\n","# plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zECJgCYhXnk2","colab_type":"text"},"cell_type":"markdown","source":["**Print the Perplexity over epochs of the currently trained model**"]},{"metadata":{"id":"QbI7xOAGfuQ3","colab_type":"code","colab":{}},"cell_type":"code","source":["perp = [ math.exp(loss) for loss in history_dict['loss']]\n","val_perp = [ math.exp(loss) for loss in history_dict['val_loss']]\n","\n","print (\"perplexity:\", perp)\n","print (\"validation perplexity:\", val_perp)\n","plt.plot(perp)\n","plt.plot(val_perp)\n","plt.title('Model Perplexity')\n","plt.ylabel('Perplexity')\n","plt.xlabel('Epoch')\n","plt.legend(['Train perplexity','Validation perplexity'], loc='upper right')\n","#plt.legend(['Train perplexity'], loc='upper right')\n","plt.rcParams[\"figure.figsize\"] = (15,10)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vnr06fIo-0DH","colab_type":"text"},"cell_type":"markdown","source":["# SAVED GRAPH SECTION"]},{"metadata":{"id":"K2pHLK-jTYLu","colab_type":"code","colab":{}},"cell_type":"code","source":["# perp = \n","# print (\"perplexity:\", perp)\n","\n","# plt.plot(perp)\n","# plt.title('Condtional Model Perplexity')\n","# plt.ylabel('Perplexity')\n","# plt.xlabel('Epoch')\n","# plt.legend(['Train perplexity'], loc='upper right')\n","# plt.rcParams[\"figure.figsize\"] = (15,10)\n","# plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IbNQ2jIP-2re","colab_type":"code","colab":{}},"cell_type":"code","source":["perp = [16.348418804440428, 10.283687330824307, 8.709842266083166, 7.916933568645355, 7.421489441782192, 7.0404791701003795, 6.739283222542519, 6.494184203938808, 6.2912496292069084, 6.130500311274162, 5.979295128491181, 5.847670846711126, 5.723765428966378, 5.62163165469696, 5.564947735036407, 5.4318938885554395, 5.364175970852322, 5.278832602977237, 5.2275725617891355, 5.159435395295851, 5.099691699359824, 5.035057344278189, 4.984605179391719, 4.940551927997494, 4.898210505625583, 4.856868933861249, 4.811558244906741, 4.770864561923012, 4.742223147979551, 4.705998821525545, 4.682146592487723, 4.6624839233195665, 4.616949919113042, 4.584394430807733, 4.564513030359467, 4.535377087525101, 4.5187681067763386, 4.500901572786341, 4.468717659964723, 4.447586923984543, 4.4373699989993876, 4.415552215277983, 4.397534535170213, 4.384635703645977, 4.372508947468803, 4.34837393164133, 4.34370858916281, 4.321766889744905, 4.312977204539631, 4.297035166427873]\n","val_perp =[11.221486041894705, 8.640195844811451, 7.65738402690025, 7.155362349899574, 6.741637624743697, 6.5032339376385675, 6.312858631201043, 6.173395964670178, 6.021321080286697, 5.948594937527857, 5.8527591407302175, 5.790766084590234, 5.755720707315652, 5.784654767761994, 5.67536758977052, 5.662697454412181, 5.662634228800737, 5.654726348535229, 5.595754074359111, 5.635172115609468, 5.617537464400125, 5.616668595403047, 5.576405135485581, 5.573847885684787, 5.670847266572062, 5.603106438476108, 5.644738358120938, 5.5908614390470195, 5.6311269157846295, 5.609611333536659, 5.687124503827853, 5.647082764722481, 5.674957354060339, 5.663237839885458, 5.689583701120254, 5.736930756141362, 5.6923525847762315, 5.731692069938086, 5.739202543210095, 5.732914151733973, 5.7313379869139975, 5.756671105145688, 5.743319866446593, 5.792162975412888, 5.783097921228845, 5.799358457756594, 5.785352625979515, 5.778316651320201, 5.809363764388644, 5.874493685157506]\n","\n","#print (\"perplexity:\", perp)\n","#print (\"validation perplexity:\", val_perp)\n","plt.plot(perp)\n","plt.plot(val_perp)\n","plt.title('Condtional Model Perplexity')\n","plt.ylabel('Perplexity')\n","plt.xlabel('Epoch')\n","plt.legend(['Train perplexity','Validation perplexity'], loc='upper right')\n","plt.rcParams[\"figure.figsize\"] = (10,8)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EI1t8oPGXrdA","colab_type":"text"},"cell_type":"markdown","source":["**Code to print model graph**\n","- note that the libraries must be installed and the runtime restarted in order for the pydot error to not be thown"]},{"metadata":{"id":"UWb8J3Kt_ptR","colab_type":"code","colab":{}},"cell_type":"code","source":["# !pip install -q pydot\n","# !pip install graphviz \n","# !apt-get install graphviz\n","\n","# from keras.utils import plot_model\n","# plot_model(model, to_file='model.png')"],"execution_count":0,"outputs":[]}]}